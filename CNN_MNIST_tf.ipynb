{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\David\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-41c901336924>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------fun used for CNN---------------------------------------------\n",
    "def Weight_Vairable(shape):\n",
    "    init = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init)\n",
    "def Bias_Variable(shape):\n",
    "    init = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "def Conv_2D(x, W):\n",
    "    return tf.nn.conv2d(x,W, strides=[1,1,1,1], padding='SAME') # strides = [1,x_stride,y_stride,1]\n",
    "\n",
    "def Pool(x, stride_val = 2, ksize_val = 2,method = 'max'):\n",
    "    if method == 'max':\n",
    "        return tf.nn.max_pool(x, ksize=[1,ksize_val,ksize_val,1], strides = [1,stride_val,stride_val,1], padding='SAME')\n",
    "    elif method == 'mean':\n",
    "        return tf.nn.avg_pool(x, ksize=[1,ksize_val,ksize_val,1], strides=[1,stride_val,stride_val,1], padding = 'SAME')\n",
    "# --------------------------------------fun used for CNN---------------------------------------------\n",
    "# define the common neural net layer\n",
    "def add_nn_layer(data, n_features, n_units, keep_prob =None ,activation = None):\n",
    "    W = tf.Variable(tf.truncated_normal([n_features, n_units],stddev=0.1))\n",
    "    Bias = tf.Variable(tf.ones([1,n_units])/5)\n",
    "    Wx_plus_b = tf.matmul(data, W) + Bias\n",
    "    if keep_prob != None:\n",
    "        Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)\n",
    "    if activation == None:\n",
    "        return tf.nn.relu(Wx_plus_b)\n",
    "    else:\n",
    "        return activation(Wx_plus_b)\n",
    "\n",
    "def cal_accuracy(x,y):\n",
    "    predict_prob = sess.run(nn_ly2, feed_dict = {xs:x, keep_prob:1})\n",
    "    compare = tf.equal(tf.argmax(predict_prob, 1), tf.argmax(y,1))\n",
    "    result = tf.reduce_mean(tf.cast(compare, tf.float32))\n",
    "    return sess.run(result, feed_dict = {xs:x, ys:y, keep_prob:1})*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Now is at step 0\n",
      "The loss = 572.5155639648438\n",
      "The testing accuracy : 12.33\n",
      "-------------------------------------------------\n",
      "Now is at step 100\n",
      "The loss = 39.60729217529297\n",
      "The testing accuracy : 88.38\n",
      "-------------------------------------------------\n",
      "Now is at step 200\n",
      "The loss = 20.35727310180664\n",
      "The testing accuracy : 92.81\n",
      "-------------------------------------------------\n",
      "Now is at step 300\n",
      "The loss = 23.094093322753906\n",
      "The testing accuracy : 94.49\n",
      "-------------------------------------------------\n",
      "Now is at step 400\n",
      "The loss = 7.517819404602051\n",
      "The testing accuracy : 95.35\n",
      "-------------------------------------------------\n",
      "Now is at step 500\n",
      "The loss = 19.28399658203125\n",
      "The testing accuracy : 95.98\n",
      "-------------------------------------------------\n",
      "Now is at step 600\n",
      "The loss = 14.829869270324707\n",
      "The testing accuracy : 96.33\n",
      "-------------------------------------------------\n",
      "Now is at step 700\n",
      "The loss = 13.683694839477539\n",
      "The testing accuracy : 96.73\n",
      "-------------------------------------------------\n",
      "Now is at step 800\n",
      "The loss = 21.963214874267578\n",
      "The testing accuracy : 96.94\n",
      "-------------------------------------------------\n",
      "Now is at step 900\n",
      "The loss = 10.371323585510254\n",
      "The testing accuracy : 97.11\n"
     ]
    }
   ],
   "source": [
    "# start construting the cnn\n",
    "xs = tf.placeholder(tf.float32, [None, 784])\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# reshape the input images\n",
    "x_image = tf.reshape(xs, [-1,28,28,1]) # [n_smaples, x_dim, y_dim, n_chanels]\n",
    "\n",
    "# hidden layer1\n",
    "W_ly1 = Weight_Vairable([5,5,1,32]) # shape = [k_size_x, k_size_y, n_chanels, n_kernels]\n",
    "Bias_ly1 = Bias_Variable([32])\n",
    "conv_ly1 = tf.nn.relu(Conv_2D(x_image, W_ly1) + Bias_ly1) # 28X28X32 images get\n",
    "pool_ly1 = Pool(conv_ly1, method='max') # 14X14X32 images get\n",
    "# hidden layer2\n",
    "W_ly2 = Weight_Vairable([5,5,32,64])\n",
    "Bias_ly2 = Bias_Variable([64])\n",
    "conv_ly2 = tf.nn.relu(Conv_2D(pool_ly1, W_ly2)+Bias_ly2) # 14X14X64 images get\n",
    "pool_ly2 = Pool(conv_ly2, method='max') # 7X7X64 images get\n",
    "\n",
    "# build the nn layer1\n",
    "pool_ly2_flat = tf.reshape(pool_ly2, [-1, 7*7*64])\n",
    "nn_ly1 = add_nn_layer(pool_ly2_flat, 7*7*64, 1024, keep_prob, None)\n",
    "# build the output layer2\n",
    "nn_ly2 = add_nn_layer(nn_ly1, 1024, 10, None, activation=tf.nn.softmax)\n",
    "\n",
    "# entropy\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(nn_ly2)))\n",
    "train_step = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict = {xs:batch_xs, ys:batch_ys, keep_prob:0.5})\n",
    "    if step % 100 == 0:\n",
    "        print(\"-------------------------------------------------\")\n",
    "        print(\"Now is at step {}\".format(step))\n",
    "        print(\"The loss = {}\".format(sess.run(cross_entropy, feed_dict = {xs:batch_xs, ys:batch_ys, keep_prob:1})))\n",
    "        #print(\"The training accuracy: {:.2f}\".format(cal_accuracy(mnist.train.images, mnist.train.labels)))\n",
    "        print(\"The testing accuracy : {:.2f}\".format(cal_accuracy(mnist.test.images, mnist.test.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Path =  ./CNN_MNIST_tf/save_net.ckpt\n"
     ]
    }
   ],
   "source": [
    "# to save the all data\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"./CNN_MNIST_tf/save_net.ckpt\")\n",
    "print(\"Save Path = \", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
